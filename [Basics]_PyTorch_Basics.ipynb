{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[Basics]_PyTorch_Basics.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNAq0qZwIL9/HFGnd+Gf7db",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "31d8e14c63bc497892f433b697b70249": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_123086f9cc8f4625922c2ea30b8de00d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b8983e9d729148799c0f79fc150c604d",
              "IPY_MODEL_0a22c3a487294b4e8d6d1119d930ec6e"
            ]
          }
        },
        "123086f9cc8f4625922c2ea30b8de00d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b8983e9d729148799c0f79fc150c604d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_16972b49966141ba961bdda803da4334",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 46827520,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 46827520,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f3cefae8a4d74b6a877b151b8d7956d7"
          }
        },
        "0a22c3a487294b4e8d6d1119d930ec6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d82022e33c3348afa7c7cec2d7c09d4b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 44.7M/44.7M [00:52&lt;00:00, 897kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b9ff11a0d9bb4b13bcf8921283038947"
          }
        },
        "16972b49966141ba961bdda803da4334": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f3cefae8a4d74b6a877b151b8d7956d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d82022e33c3348afa7c7cec2d7c09d4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b9ff11a0d9bb4b13bcf8921283038947": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vvvu/potential-chainsaw/blob/main/%5BBasics%5D_PyTorch_Basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lkLNeCR5-b5"
      },
      "source": [
        "## 1. Basics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nI2K9mxZ6DGt"
      },
      "source": [
        "### 1.1 PyTorch Basics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26sqxfOR6F1m"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "'''\n",
        "1. torchvision.transforms是PyTorch中的图像预处理包，包含了很多种对图像数据进行变换的函数\n",
        "'''\n",
        "import torchvision.transforms as transforms\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bn_ZbayC6MUL",
        "outputId": "7f3f07a0-3a75-4e19-a76b-0057140d1c80"
      },
      "source": [
        "# Create tensors\n",
        "x = torch.tensor(1., requires_grad = True)\n",
        "w = torch.tensor(2., requires_grad = True)\n",
        "b = torch.tensor(3., requires_grad = True)\n",
        "'''\n",
        "1. requires_grad是PyTorch中Tensor的一个属性，用来说明当前量是否需要在计算中保留对应的梯度信息，\n",
        "如果requires_grad = False，则梯度无法回传，训练失败\n",
        "'''\n",
        "\n",
        "# Build a computational graph\n",
        "y = w * x + b # y = 2 * x + 3\n",
        "\n",
        "# Compute gradients\n",
        "y.backward()\n",
        "\n",
        "# Print out the gradients\n",
        "'''\n",
        "我们之前定义的函数为 y = w * x + b\n",
        "（1）对x求梯度结果为其系数w, 即x.grad = w = 2\n",
        "（2）对w求梯度结果为其系数x, 即w.grad = x = 1\n",
        "（3）对b求梯度结果为其系数1, 即b.grad = 1\n",
        "'''\n",
        "print(x.grad) # x.grad = 2\n",
        "print(w.grad) # w.grad = 1\n",
        "print(b.grad) # b.grad = 1"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.)\n",
            "tensor(1.)\n",
            "tensor(1.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovC_GvXh7YQp",
        "outputId": "d08f4b0f-9b4c-4d90-d1cb-3e18c8723fbc"
      },
      "source": [
        "# Create tensors of shape (10, 3) and (10, 2)\n",
        "'''\n",
        "torch.randn : Returns a tensor filled with random numbers from a normal distribution\n",
        "with mean `0` and variance `1` (also called the standard normal\n",
        "distribution).\n",
        "'''\n",
        "x = torch.randn(10, 3) \n",
        "y = torch.randn(10, 2)\n",
        "\n",
        "# Build a fully connected layer\n",
        "linear = nn.Linear(3, 2) # matrix (10,3) x (3,2) = (10,2) => w * x + b => y\n",
        "print('w: ', linear.weight)\n",
        "print('b: ', linear.bias)\n",
        "\n",
        "# Build loss function and optimizer\n",
        "criterion = nn.MSELoss() # Loss Function\n",
        "optimizer = torch.optim.SGD(linear.parameters(), lr = 0.01)\n",
        "'''\n",
        "optimizer优化器的参数非常直观：\n",
        "(1) 待优化model的所有参数parameters()\n",
        "(2) 学习率learning_rate\n",
        "'''\n",
        "\n",
        "# Forward pass\n",
        "pred = linear(x)\n",
        "\n",
        "# Compute loss\n",
        "loss = criterion(pred, y)\n",
        "print('loss: ', loss.item())\n",
        "'''\n",
        "The item() method extracts the loss’s value as a Python float.\n",
        "'''\n",
        "\n",
        "# Backward pass\n",
        "loss.backward()\n",
        "\n",
        "# Print out the gradients\n",
        "print('dL/dw: ', linear.weight.grad)\n",
        "print('dL/db: ', linear.bias.grad)\n",
        "\n",
        "# 1-step gradient descent\n",
        "optimizer.step()\n",
        "'''\n",
        "`optimizer.step` performs a parameter update based on the [current gradient]\n",
        "(which stored in `.grad` attribute of a parameter) and the update rule\n",
        "'''\n",
        "\n",
        "# Print out the loss after 1-step gradient descent.\n",
        "pred = linear(x)\n",
        "loss = criterion(pred, y)\n",
        "print('loss after 1 step optimization: ', loss.item())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "w:  Parameter containing:\n",
            "tensor([[-0.4947, -0.4644,  0.2885],\n",
            "        [ 0.5699, -0.3475, -0.1600]], requires_grad=True)\n",
            "b:  Parameter containing:\n",
            "tensor([-0.0283,  0.4911], requires_grad=True)\n",
            "loss:  1.128941297531128\n",
            "dL/dw:  tensor([[-0.5392, -0.1337, -0.4095],\n",
            "        [ 0.2882, -0.2899,  0.1438]])\n",
            "dL/db:  tensor([-0.0459,  0.8059])\n",
            "loss after 1 step optimization:  1.1158812046051025\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYnNSQQo8AHD"
      },
      "source": [
        "# Loading data from numpy\n",
        "\n",
        "# Create a numpy array\n",
        "x = np.array([[1, 2], [3, 4]])\n",
        "\n",
        "# Numpy array => Torch tensor\n",
        "y = torch.from_numpy(x)\n",
        "\n",
        "# Torch tensor => Numpy array\n",
        "z = y.numpy()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vs0CMrNg_qMy",
        "outputId": "2c4ea000-c382-4573-aba5-09c0909f2230"
      },
      "source": [
        "# Input pipeline\n",
        "import torchvision.transforms as transforms\n",
        "# Download and construct CIFAR-10 dataset.\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train = True, \n",
        "                                             transform = transforms.ToTensor(),\n",
        "                                             download = True)\n",
        "\n",
        "# Fetch one data pair (read data from disk)\n",
        "image, label = train_dataset[0]\n",
        "print(image.size(), label)\n",
        "\n",
        "# Dataloader (this provides queues and threads in a very simple way)\n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
        "                                           batch_size = 64,\n",
        "                                           shuffle = True)\n",
        "\n",
        "# When iteration starts, queue and thread start to load data from files\n",
        "data_iter = iter(train_loader)\n",
        "'''\n",
        "Get an iterator from an object.  In the first form, the argument must\n",
        "supply its own iterator, or be a sequence.\n",
        "'''\n",
        "\n",
        "# Mini-batch images and labels\n",
        "images, labels = data_iter.next()\n",
        "\n",
        "# Actual usage of the dataloader is as below\n",
        "for images, labels in train_loader:\n",
        "  # [Training code should be written here]\n",
        "  pass"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "torch.Size([3, 32, 32]) 6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2XIWS8-ABqJ"
      },
      "source": [
        "'''\n",
        "How to build custom dataset\n",
        "'''\n",
        "\n",
        "# You should build your custom dataset as below\n",
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self):\n",
        "    # 1. Initialize file paths or a list of file names.\n",
        "    pass\n",
        "  \n",
        "  def _getitem__(self, index):\n",
        "    # 1. Read one data from file (e.g. using numpy.fromfile, PIL.Image.open)\n",
        "    # 2. Preprocess the data (e.g. torchvision.Transform)\n",
        "    # 3. Return a data pair (e.g. image and label)\n",
        "    pass\n",
        "\n",
        "  def __len__(self):\n",
        "    # You should change 100 to the [total size] of your dataset\n",
        "    return 100\n",
        "\n",
        "# You can then use the prebuilt data loader\n",
        "custom_dataset = CustomDataset()\n",
        "train_loader = torch.utils.data.DataLoader(dataset = custom_dataset,\n",
        "                                           batch_size = 64,\n",
        "                                           shuffle = True)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100,
          "referenced_widgets": [
            "31d8e14c63bc497892f433b697b70249",
            "123086f9cc8f4625922c2ea30b8de00d",
            "b8983e9d729148799c0f79fc150c604d",
            "0a22c3a487294b4e8d6d1119d930ec6e",
            "16972b49966141ba961bdda803da4334",
            "f3cefae8a4d74b6a877b151b8d7956d7",
            "d82022e33c3348afa7c7cec2d7c09d4b",
            "b9ff11a0d9bb4b13bcf8921283038947"
          ]
        },
        "id": "KAGqu1QOBjTH",
        "outputId": "94d54c5f-2d84-4915-bc71-f62425236833"
      },
      "source": [
        "'''\n",
        "Using pretrained model\n",
        "'''\n",
        "\n",
        "# Download and load the pretrained ResNet-18\n",
        "resnet = torchvision.models.resnet18(pretrained = True)\n",
        "\n",
        "# If you want to finetune only the top layer of the model, set as below\n",
        "for param in resnet.parameters():\n",
        "  param.requires_grad = False\n",
        "'''\n",
        "1. 通过设置最顶层的参数的required_grad = False，这样梯度回传就会在这里停止\n",
        "2. 这样我们就可以只针对顶层的参数进行调参\n",
        "'''\n",
        "\n",
        "# Replace the top layer for finetuning\n",
        "resnet.fc = nn.Linear(resnet.fc.in_features, 100)\n",
        "\n",
        "# Forward pass.\n",
        "images = torch.randn(64, 3, 224, 224) # 64 images, 3 channels, 224 * 224 \n",
        "outputs = resnet(images)\n",
        "print(outputs.size()) # (64, 100)\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "31d8e14c63bc497892f433b697b70249",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=46827520.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "torch.Size([64, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IO9_kf6GCMmj",
        "outputId": "75694012-5997-4389-fdaa-2e2bdc0c6e2a"
      },
      "source": [
        "'''\n",
        "Save and load the model\n",
        "'''\n",
        "# Save and load the entire model\n",
        "torch.save(resnet, 'model.ckpt')\n",
        "model = torch.load('model.ckpt')\n",
        "\n",
        "# Save and load only the model parameters (recommended).\n",
        "'''\n",
        "因为有的时候Model会比较大，我们倾向于只读取Model的参数\n",
        "'''\n",
        "torch.save(resnet.state_dict(), 'params.ckpt')\n",
        "resnet.load_state_dict(torch.load('params.ckpt'))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMs0xws6Ci73"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}