{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[Intermediate]_Convolutional_Neural_Network.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP86mGcwSo2ainmcJFpNNut",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vvvu/potential-chainsaw/blob/main/pytorch-tutorial/%5BIntermediate%5D_Convolutional_Neural_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YkslsgPKNbp"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpRV-PHYKYSB"
      },
      "source": [
        "# Device configuration\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFPMIIzZKd6p"
      },
      "source": [
        "# Hyper Parameters\n",
        "num_epochs = 5\n",
        "num_classes = 10\n",
        "batch_size = 100\n",
        "learning_rate = 0.01"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8Stqe8KKj07"
      },
      "source": [
        "# MNIST dataset\n",
        "train_dataset = torchvision.datasets.MNIST(root = './data',\n",
        "                                           train = True,\n",
        "                                           transform = transforms.ToTensor(),\n",
        "                                           download = True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root = './data',\n",
        "                                          train = False,\n",
        "                                          transform = transforms.ToTensor())\n",
        "\n",
        "# Data Loader\n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
        "                                           batch_size = batch_size,\n",
        "                                           shuffle = True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
        "                                          batch_size = batch_size,\n",
        "                                          shuffle = False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8iRjtrSK69j"
      },
      "source": [
        "# Convolutional Neural Network (2 convolutional layers)\n",
        "class ConvNet(nn.Module):\n",
        "  def __init__(self, num_classes = 10):\n",
        "    super(ConvNet, self).__init__()\n",
        "    '''\n",
        "    nn.Conv2d():\n",
        "    in_channels: 输入数据的通道数，例如RGB图片的通道数为3，这里为黑白MNIST，通道数为1\n",
        "    out_channels: 输出数据的通道数，根据Model调整\n",
        "    kernel_size: 卷积核大小，可以为int，多维度卷积核则为tuple\n",
        "    stride: 步长，默认为1，可以为int，多维度步长则为tuple\n",
        "    padding: 零填充\n",
        "\n",
        "    nn.BatchNorm2d():\n",
        "    Batch Normalization - 批标准化，与数据的普通标准化类似，是将分散的数据统一的一种做法\n",
        "    也是优化神经网络的一种方法，「具有统一规格的数据能让机器学习更容易学习到数据之中的规律」\n",
        "    num_features: 输入特征的数量，因为out_channels = 16,所以这里选择为16\n",
        "\n",
        "    nn.MaxPool2d():\n",
        "    nn.MaxPool2d可以提取重要信息，去掉不重要的信息，减少计算开销\n",
        "    '''\n",
        "    self.layer1 = nn.Sequential( # Sequential - 按照构造函数中传递的顺序添加到模块中\n",
        "        nn.Conv2d(in_channels = 1, out_channels = 16, kernel_size = 5,\n",
        "                  stride = 1, padding = 2),\n",
        "        nn.BatchNorm2d(16),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "    )\n",
        "    self.layer2 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels = 16, out_channels = 32, kernel_size = 5,\n",
        "                  stride = 1, padding = 2),\n",
        "        nn.BatchNorm2d(32),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "    )\n",
        "    self.fc = nn.Linear(in_features = 7 * 7 * 32, out_features = num_classes)\n",
        "    # fully connected layer\n",
        "    # in_features = 7 * 7 * 32?\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.layer1(x)\n",
        "    out = self.layer2(out)\n",
        "    out = out.reshape(out.size(0), -1) # ?\n",
        "    print(out.shape)\n",
        "    out = self.fc(out)\n",
        "    return out\n",
        "\n",
        "model = ConvNet(num_classes).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01Kp2fmrVI8r"
      },
      "source": [
        "1. 卷积层`nn.Conv2d()`\n",
        "\n",
        "   - 作用：提取一个局部区域的特征，不同的**卷积核**相当于不同的**特征提取器**\n",
        "\n",
        "   - 参数`out_channels`：代表输出频道的数量。输出频道的数量是和卷积核挂钩的。即：我们有多少个卷积核，就代表我们从原始的图片中提取了多少种特征，即代表着我们有多少可以输出的频道。**值得注意的是，这里的卷积核是自动生成的，在PyTorch中有其自定义的生成规则，我们也可以在这里自定义自己希望的卷积核。但默认情况下，这里的卷积核我们无需定义，是自动生成的。**\n",
        "\n",
        "2. 汇聚层`nn.MaxPool2d()`\n",
        "   - 作用：又名子采样层`Subsampling Layer`，其作用是进行特征选择，降低特征数量，从而减少参数数量\n",
        "   - 这里我们可以发现每一个卷积层的输出都有一个`nn.MaxPool2d()`层的参与，这里采用的是**Maximum Pooling**的方式，即对于一个区域，选择这个区域内所有神经元的最大活性值作为这个区域的表示。当我们选择参数`kernel_size = 2， stride = 2`时，相当于我们每两个格卷一下，则原始输入数据为`28 x 28 x 1`的图片，在经过`self.layer1()`后，频道增加到`16`，尺寸经过`nn.MaxPool2d()`降低为`14 x 14`。则得到的中间项为`14 x 14 x 16`。再经过`self.layer2()`后，频道增加到`32`，尺寸经过同样的`nn.MaxPool2d()`变化后变为`7 x 7`。则最后给到`self.fc()`层的输入为`7 x 7 x 32`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0y37GOlINhmJ"
      },
      "source": [
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDiq2eZQOL5l",
        "outputId": "237ffa92-a0f4-49a2-b61f-48c22447ca36"
      },
      "source": [
        "# Train the model\n",
        "total_step = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "  for i, (images, labels) in enumerate(train_loader):\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    # Forward pass\n",
        "    outputs = model(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # Backward and optimize\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (i + 1) % 100 == 0:\n",
        "      print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "            .format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Step [100/600], Loss: 0.2597\n",
            "Epoch [1/5], Step [200/600], Loss: 0.1021\n",
            "Epoch [1/5], Step [300/600], Loss: 0.0352\n",
            "Epoch [1/5], Step [400/600], Loss: 0.0787\n",
            "Epoch [1/5], Step [500/600], Loss: 0.0169\n",
            "Epoch [1/5], Step [600/600], Loss: 0.0419\n",
            "Epoch [2/5], Step [100/600], Loss: 0.1031\n",
            "Epoch [2/5], Step [200/600], Loss: 0.0295\n",
            "Epoch [2/5], Step [300/600], Loss: 0.0538\n",
            "Epoch [2/5], Step [400/600], Loss: 0.1662\n",
            "Epoch [2/5], Step [500/600], Loss: 0.0266\n",
            "Epoch [2/5], Step [600/600], Loss: 0.1016\n",
            "Epoch [3/5], Step [100/600], Loss: 0.0187\n",
            "Epoch [3/5], Step [200/600], Loss: 0.0428\n",
            "Epoch [3/5], Step [300/600], Loss: 0.0092\n",
            "Epoch [3/5], Step [400/600], Loss: 0.0724\n",
            "Epoch [3/5], Step [500/600], Loss: 0.0098\n",
            "Epoch [3/5], Step [600/600], Loss: 0.0029\n",
            "Epoch [4/5], Step [100/600], Loss: 0.0336\n",
            "Epoch [4/5], Step [200/600], Loss: 0.0160\n",
            "Epoch [4/5], Step [300/600], Loss: 0.0178\n",
            "Epoch [4/5], Step [400/600], Loss: 0.0178\n",
            "Epoch [4/5], Step [500/600], Loss: 0.0306\n",
            "Epoch [4/5], Step [600/600], Loss: 0.0031\n",
            "Epoch [5/5], Step [100/600], Loss: 0.0651\n",
            "Epoch [5/5], Step [200/600], Loss: 0.0517\n",
            "Epoch [5/5], Step [300/600], Loss: 0.0299\n",
            "Epoch [5/5], Step [400/600], Loss: 0.0144\n",
            "Epoch [5/5], Step [500/600], Loss: 0.0311\n",
            "Epoch [5/5], Step [600/600], Loss: 0.0114\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zgq7bmNOkOF",
        "outputId": "c1a0d745-bdbc-4047-d602-9994374c3ca6"
      },
      "source": [
        "# Test the model\n",
        "model.eval()\n",
        "'''\n",
        "eval mode\n",
        "- batch norm uses moving mean/variance instead of mini-batch mean/variance\n",
        "\n",
        "- eval() sets the module in evaluation mode. [This has any effect only on certain\n",
        "modules. They will (1)make normalization layers use running statistics \n",
        "(2) deactivates Dropout layers]\n",
        "\n",
        "- The difference between `model.eval()` and `with torch.no_grad()`\n",
        "I. `model.eval()` will notify all your layers that you are in eval mode, that way,\n",
        "[batchnorm or dropout] will work in eval mode instead of training mode.\n",
        "II. `torch.no_grad()` impacts the autograd engine and deactivate it. It will reduce memory\n",
        "usage and speed up computations but you won't be able to BP(backprop) [which you\n",
        "don't want in an eval script]\n",
        "'''\n",
        "with torch.no_grad():\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  for images, labels in test_loader:\n",
        "    images = images.to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(images)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "\n",
        "  print('Test Accuracy of the model on the 10000 test images: {}%'.format(100 * correct / total))\n",
        "\n",
        "# Save the model checkpoint\n",
        "torch.save(model.state_dict(), 'model.ckpt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy of the model on the 10000 test images: 99.11%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}